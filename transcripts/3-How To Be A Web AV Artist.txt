"How To Be A Web A/V Artist"
Ruth John

RUTH:  I need to make sure the sound...
    >> Great.  So we're ready to go.  Please welcome Ruth!
    RUTH:  Oh, hello, JSConf!  That's an exclusive for everybody who's sitting here because they're going to have to cut it out of the video.  I am so sorry!  I don't have the right to play that music.  But I really, really wanted to!  It's fine, it's at the beginning, they can cut that out.  Hi.  I'm Ruth.  This is the part of the talk where I tell you where I'm from, what I do, who I am.  I think I kind of just did that.  So, hi, I'm Ruth.  I'm here today to talk to you about how to be a web AV artist.  Yeah... I know.  I know.  To be honest with you, I struggled with the practicality of this talk.  I'm going to be talking about WebAudio API, and MIDI API and I don't know how many of you are going to go back to work on Monday and put the word "MIDI API" into a website.  So I kind of thought to myself when I saw this about six months ago, that I should take it literally.
    This is a Venn diagram.  This is a Venn diagram about practical talks at conferences.  And on the left-hand side, you've got what people actually talk about, and you've got on the right-hand side, what attendees want you to talk about.  So I made two lists just to make sure that this is a really useful talk, by the way, I made two lists.  One list is things that I have to avoid talking about, and the other list is things that I have to include in this talk.
    And then it would be really, really useful for all of you, and my talk anxiety will go away.  So I have to avoid analytics, operational excellence, chat ops, orchestration.  That's fine.  I think I can totally avoid these things.
    I have to include duct tape, workarounds, bike shedding, and coffee, and tea.  Easy things to include for a developer.  Great.  Now that I've got that out of the way, let's begin.  So what is an AV artist?  AV stands for audio- visual.  So as an audio-visual artist, it's just taking some audio and making visualizations from that audio.  Another name for this is a VJ.  There's not a lot of making the audio.  We're just taking what other people are making and using the data from it.  Who, out there, remembers this?
    >> Winamp!  It really whips the llama's ass!
    RUTH:  For those of you who don't remember, because there are going to be a few people who don't remember, this is the best mp3 player of all the time.  It's lightweight, and easy to install and quick, and free, but it actually played music that you had on your hard drive.  It's amazing.  But that was not the best thing about Winamp.  This was the best thing about Winamp.  So you could whip up these visuals and they would go in time to the music and you could just sit and watch for hours.  This was probably the most influential thing of any VJ of my generation and this is kind of what got me into it.  I said, I want to make this!  This is great!  So the first thing that we need to make things like this is audio and that's good.  We have a Web Audio API.  And that gets us audio.  That's great.  There's four main ways that you can do it with the Web Audio API.  I'm sure you've come across most of these.  So you can create sound yourself.  And so you instigate an oscillator, and you can grab elements from the DOM.  If you have audio-video element in the DOM, you can pipe it from that.  You can stream it, and that's usually taking it from the camera, or the microphone from your laptop and you can stream it into the audio API, or you can go get a sound file and buffer the data from that sound file.  So what you're doing is taking the data and putting it in sort of a container that the audio API has, and then you can use the data.  I'm using the Fetch API as an example here to go and get my sound file.
    So a couple of examples.  This one, I'll taking the sound from a sound file.  I'm just piping it in and it's analyzing that.  And this one is actually picking up on my voice.  So it's picking up the microphone from my laptop, and streaming it into the audio API.  This is my preferred method for the moment because I don't know where I'm going to be doing the visualizations.  And so we need to be able to analyze the sound.  Oh, okay.  I'm not allowed to say "analytics."  That was a -- thank you very much, Turk.  It's going to trip me every single time whenever this is said.  But I'm talking about analytics.  So to analyze sound, we can do it at the Web Audio API level, as well, and we can do that with the analyzer node and we can use the sound that we created, or got with the audio API and it would give us analyzed data back, and what it gives us is something like this, which is an array of frequency velocities.  For those of you who don't know what that means, frequency is sound levels.  It's like low sounds to high sounds.
    And what we're actually scanning for here is naught hertz to 30,000 kilohertz, that's very, very high.  And that's higher a resolution than we can actually detect and the velocity of the volume is just the frequency of that volume at any given point and it's just a number and then we can just use those numbers, which is exactly what's going on here.  This is just a bunch of i-elements and I'm taking that data value, that velocity value, and I'm making it the height of those i-elements.
    It's really rather straightforward.  Just loop through these, great.  We can all make visuals and my talk is over and we can go for an early lunch.  We could actually do some more complicated stuff.  But it is relatively easy and we're just using HTML, CSS, and JavaScript, actually just to do something really cool.  So I wondered how far could we really take this with just these technologies and I started a bunch of experiments.  And everybody knows when you start experimenting, you need some inspiration.  So this was my first inspiration.  This is Bridget Riley, she's a super cool artist.  It said so on the slides.  I actually discovered her at ScotlandJS there, and she had an exhibition at Edinborough, and it was really, really great and I said, I'm going to visualize paintings.  And these are all divs, and I'm just using Flexbox, and I'm getting the data back.  It's just really simple.  And this one is another one showing some triangles based on that data.  And this is just simply stuff in the DOM.  And, of course, if we're using things in the DOM, we can try and instigate some lovely CSS because I'm at a JavaScript conference, so I thought I would bring in some CSS, I thought that would be a really, really good idea.  Transforms are cool.
    With visualizations, I really feel like you could do some symmetry.  If I could take whatever's in the DOM and replicate it, and rotate it around with just the function, then I could do whatever I have in the DOM.  That would be really great.  That would let me do whatever I want to do the set.  So I did that, and so I've got literally one-quarter of the screen.  And I thought, well, we could put anything in the DOM.  And that's a good thing, as well because you want to be able to use videos and imagery, so I thought, wouldn't it be cool if we could just drop a gif in one of these quarters and reflect and rotate that around?  And you can do that, as well.  This is a My Little Pony gif.  My favorite kind of gif.  And so on and so forth of the lovely CSS things we have are blends and filters.  So the visualization that we have at the top of the show, we can just add some blend modes to that, and we've got a much nicer visualization -- well, I think the first one was pretty good.  But this one has just got some blend modes on.  So each element is just fighting for the next element.  Top tips for you, filters, filters, if you're unaware in CSS of things like saturation, inversion, and things like that, work on video, so if you are playing video clips in your set, you can invert with literally just a CSS property which works really, really well.  It's really good.
    One CSS thing which is actually really, really interesting, and something that was great to experiment with was custom properties.  Now we've got a lot of data and we've got a lot of data in our JavaScript but we might be styling with CSS.  So it's almost like, well, okay, we can change styles in JavaScript, that's fine.  But this is an interesting one.
    I'm sure everybody has seen this but I am just going to go over it.  If you've ever used a CSS preprocessor, so SASS, or LESS, or something like that, you probably have come across variables.  This is almost the same idea in spec.  So at the top there, we've got some CSS, and you declare whatever you want your variable in the root element, with a dash, dash and then whatever you want.  This level that I have in mind is going to reflect the frequency data which I'm getting from the analyzer node and then all I'm doing is changing the width and the height later on in the CSS.  And then in the JavaScript, I could parse that frequency data back to my CSS.  So I can do this with document.element.* property.  So it can update in real time, and this is all in JavaScript and CSS but it's very, very handy.  And again, it can come in very, very handy for effects.  So I did this.  This is an example of all the things that you've just seen.  You've got some DOM elements, you've got some blend modes, you've got some custom properties going on.  What you might notice is it's a little bit janky.  It doesn't really like operating.  Uh, now let's talk about operational excellence.  It's okay.  We're halfway through the talk, 50%.  Who knows which way this is going to go.
    Okay.  I'm not allowed to talk about chat ops, or orchestration.  Okay, okay.  So yeah, this is a little bit, yeah, janky, and I was thinking about performance.  This is my friend, Ben.  It's really, really good to talk to your friends and not just for rubber-duckying when you have bugs in your code but when you're considering the overall thing that you're building and the best way and all the stuff, it's really good to chat -- oh, chat ops.  I couldn't avoid orchestration.  I could totally avoid orchestration.  It's fine.  This will be a really useful talk, I promise you.  So I was talking to Ben and he was talking to me about the interactive piece that he was doing which was very similar to the stuff that I'm talking to you about, and we went over performance because the performance wasn't going over very well.  And he said to me, maybe I should use D3.js.  Now I usually don't use libraries unless I have to.  But it kind of made sense because D3 is a visualization library.  And when a lot of people think of D3, they think of bar charts, and visualized data.  But that's what it does well.  I have some data and I want to visualize it.  It's also good for maths I'm working with numbers a lot.  And it's very good with the DOM and it's helpful because that was kind of what was hindering performance.  And I could use SVGs because that's really, really nice for the render.  So that begins experiment number two.  This is my inspiration for experiments number two.  This is called Super Graphic by Tim Leon.  And it charts data from graphic novels.  So stuff like this starts happening.  So this is a basic sunburst chart but it's just picking up on my voice and it's making a nice visualization.  Ooh, it's coming up on all the screens.  That's cool.  I quite like screens and projectors, you might have guessed.
    And things like this, which is also lovely.  And there's quite a few.  So we can sort of reimagine the spectrum that we saw earlier and we can have circles instead.  And that be can a nice thing to be mixing into a set when we actually get to the end and we do that.
    This is one of my favorites, actually.  It's just a nice little circle.  It has little rainbow colors.  I wanted to just, for a second, go back to analysis.  Um, and this is just before we have lunch.  Engage brain, or try and make this make sense.
    If we take this array of frequency velocities that we were talking about at the beginning of the talk, there is one thing about it.  It goes from naught hertz to 20,000 Hz.  This is a keyboard, or a piano.  This is where it sits on that frequency scale.  It only goes up to about 6,000 Hz.  I'm not trying to give the experience of the notes.  I'm trying to give a visualization based on the music that is being played.  So I can use this as a guide and I can think, actually, that kind of top part of the array, I probably don't need that.  It's probably not being used in music that we listen to.
    The other thing to note about this are you aware is it goes up in even steps.  So each item is going to be, like, an even step of the last one.  That's not how notes work.  So this is a keyboard.  I've highlighted some keys, A, on a keyboard, keys that are denoted in the letters, H, G, and they start again, so an A, and an A, and they're octaves apart and we say octaves because there's two As, and -- so this middle key here, this orange key, this is A.  This runs at 440 Hz.  The one below it, the purple A, runs at 220 Hz.  That's a 220 Hz gap.  The one above it, however, the green one, runs at 880 Hz.  So that's a 440 Hz gap, they're not equaling, they're doubling.  So to get a better analysis from the audio that we get from the API, we want to kind of do something like this.  We slice the array.  We kind of don't need that data, there's no point.  Having it, and then I need to spread it out.  So imagine function.  It's too close to lunch.  I won't go through it.  And it is on the Internet -- I've written an article about it.  So we're pushing this new data back into the data so just to confirm, I'm going to do it -- we've got seven and a half minutes left!  And I've got a couple of examples for you.  So this is -- let me just -- there we go.  This is a visualization before I do anything on the data, and you can see that it's quite heavy towards the right.  So this is where the analysis starts, is on the right.  Afterwards, after we've run the function, we get something a little like this, which is much more spread out, and I think works better as a visualization and also it's going to be good if I want to do anything like low, middle, and high frequency detection because I can actually do it on the music that's basically playing, not the data that we get back from the audio API.  So we have visualizations.  That's the crux of it.  You can all go in and make visualizations.  That's great.  I did some code that are not the final versions that I want to use, so you can go on CodePen, and have a look.  One last thing, I'm checking my time here.  How do I control these visuals?  That's important, I'm going to be playing sets.  And you're going to be playing sets of DJs, and they're going to be controlling stuff like decks and stuff.  And try the Gamepad API.  But the Gamepad, that's a little bit funky, and there's not a lot of control on the game pad.  So there's the '80s API.  It's a data protocol for instruments to talk to each other.  And it came around 1993, and instruments manufacturers came together because there was a rise in electronic instruments in the '70s, and they said, wouldn't it be nice if these all could talk to each other, and they came up with this spec, the MIDI.  This is a MIDI instrument.  The big difference between a MIDI instrument and what I'm about to show you is this has onboard audio.  I can plug this into my computer, and it would send MIDI data, but it also plays data standard alone but it can also talk to other instruments and orchestrate with those.
    We are so close to the end of the talk now.  Useless talk.  Never mind.  Never mind, haha.  MIDI instrument.  The big difference between these and what you're probably more likely to see and want to use, which is this, is this is a MIDI controller.  This doesn't have any onboard audio but it's still sending MIDI data so if you plug this into your computer and run some code like this, which is the Web MIDI API, you can pick up on the data it's sending, which is, again, just numbers and that's really cool.  There's lots and lots of different MIDI controllers out there and if you search for them, you'll come up with loads of them and I recommend buying them and trying out that code because it's really fun.  This is my MIDI controller, this is my Minin, this is the little one that I carry around in my handbag.  This finds on Bluetooth, they used to run on DIN which was a round fat cable that which some of you might remember.  Hope that the gods are being kind to me, I can use this to mix... it's worth in there but not in here.  Let's see if that one will.
    No.  It's not happening today.  I can use this to mix my visuals and change them.  So I can attach all the different things that I've made for the different buttons and then choose which ones come up at different times and then I can mix from one into the other, which is great.  Whoo.  Is any of this real?  Kind of seems silly, doesn't it?  I'm making crazy visualizations in the browser, and controlling them with little boxes of light pads.  This is me.  I have a little pocket projector.  So I put my laptop and my MIDI controller and my projector in the bag, and I've kind of hacked the bag so you can unzip it, and kind of carry it around like an usherette tray, and so you can carry it around, and this is me projecting it on my local streets in my city.  And I did this.  This is a real thing.  And this is running the software all in a browser and some people started talking to me on the Internet -- the Internets are good.
    And things like this happened.  So there's a whole bunch of us doing similar things, taking web technologies and building things with it.  They build music software with JavaScript, they control lights with JavaScript.  I don't know whether you saw nested loops at the beginning of today, one of the guys, Martin, he was controlling all the lights via DMX, with JavaScript.  LiveJS.network if you have to check us out.  We have a stand with lots of MIDI controllers and we have lots -- and the music that you hear between the breaks that's us.  And if you've got a GitHub organization, you gotta be real.  If you've got a GitHub organization, that's, like, a badge of reality right there.  And we play gigs.  We're not just together at conferences, but we actually play gigs.  So I can go do my day job and go and play a gig.  Madness!  We got to play a festival over the summer.  There is one thing that I really, really want to address before I go, and that's this.  You see, I don't think that my talk really picked up on what was really going on, and I'm sure you guys did, right?
    The keen among you will realize... um, sound?  Nope?  Okay.  There was duct tape holding the portable VJ kit together.  Of course there's duct tape holding everything together!  Then, it's on a bike!  Yes!  Still more sound!
    This whole function is a workaround!  Yeah!  And -- drinking coffee!  Thank you very, very much.  All the music that you heard was by Canera.  I recommend that you look her up on Soundcloud.  And I'm @ruthjohn on the Internet.  Come and talk to me over there!
    
    [ Applause ]
    
    >> Thank you so much, Ruth, that was super inspiring and really awesome, and I'm totally going to check out your booth later.  So it is lunch.  Who's hungry?  There's food and there's also talks and community events and other stuff.  There's so much going on in the festival area.  If you want to find out more about Code Mirror, and UX School at Knight, there's going to be a community lunch during lunch -- a community talk during lunch.  And there's also going to be a Rust Q&A at the Mozilla sponsor booth, and there'll be other things going on at the sponsor booth.  So lots of things going on.  Check it out.  And we'll see you after lunch, in an hour.  See you guys at 2:00!
    
    [ Lunch Break ]
    
    Also we sometimes have these slides saying that the talks are starting at 11:15.  Sometimes the slides are wrong.  The Internet schedules are right.  If you're confused, follow the Internet schedule. 
