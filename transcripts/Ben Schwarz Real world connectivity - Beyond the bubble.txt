Ben Schwarz Real world connectivity - Beyond the bubble 
>> One did my favourite things about both JSConf and CSSConf is this warm and fuzzy feeling you get when you come here, like a family reunion without the bad parts!  I love that. I've been coming for I think four years, and every single time, it is even more amazing, and more people are getting into this nice family of ours. Ben is a really good example of that. He not only runs JSConf back in Australia, but he's been coming here for three or four years. He mc'ed two of them, and now he's speaking so it comes around. You can end up attending and then speaking, which is really great. You can be on the stage. Yes, Ben is from Melbourne in Australia which is a great city. I lived there, too. He's a founder of Calibre which is a web-performance monitoring tool and he will tell you about the state of connectivity, the state of the internet and what we can do for people to make the internet and web faster for them. Please give a really washing welcome to Ben Schwarz. [Applause].  
BEN:  Hello!  How are we doing?  Doing good?  My mother doesn't know what I do, so this isn't going to help her, but if everyone can just yell "ya" as I come around, okay?  
AUDIENCE:  Ya. 
BEN:  Mum ... I don't know!  [Laughter]. That was fun. My name is Ben Schwarz.  I'm from Melbourne, Australia. I've been coming here for a few years and it's my favourite conference anywhere in the world to come. It is a huge privilege. Thanks for everyone for making it great for me to be here. My talk today is called "Beyond the Bubble" and I hope to achieve, to give you some context that maybe you haven't maybe necessarily considered as part of your day jobs. When we usually talk about performance, we talk about how quickly pages load, we talk about how much money Amazon made when they made something half a second faster, but often, that's kind of really as far as we go, I think is really sad because performance is a pillar of user experience, and yet every aspect of performance work we are doing right now seems to be a bit of an afterthought. Sites are often deployed to production, and then we say all right, let's see how this performance. And if the result are disappointing, then maybe do our best to see what we can do. But often we have to just move on because there isn't the time and budget, and nobody is really committed to it by that point. And we are still, when we're doing this, when we're building the sites and apps and these experiences, we are doing doing using a $3,000 dollar computer or a $1,000 phone and you're doing it on localhost. Of course it is going to be fast. I think it is our -- doing it on localhost. I am the founder of a company called Calibre, a recently young company. It is so young, in fact, that I'm the only person in the company. I do everything. What that really means is I'm full-time now. I became full-time in January, and ultimately, that means that every day, I am helping to build tools to make the web faster, or helping to try to contribute to that, or I'm doing audits for people, or I'm diving in stack traces. I'm kind of doing that performance work that you would maybe do if you had the time, but that's all I'm doing right now. I hope through that you will maybe enjoy the talk ahead. So, I thought it would be really interesting look at somewhere where time really equalled money, and in the last 30 years, we've been trying to reduce latency between locations, but somewhere it was really hyperfocused was in the stock changes between Chicago and New York. Every few milliseconds you save or make literally billions of dollars. In the made 1980s, the round-trip latency was 14 and a half milliseconds, cut by a millisecond and a half in 2010 by shortening the physical fibre route they took. They thought this is too slow and we will do something else. [Sound cut] you see that large tower there. That's a microwave tower. These towers - using these towers, they were able to get that connection speed right down to 4.2 milliseconds which is a huge improvements, three times over where we started in the 1980s. Interestingly enough, when these towers were constructed, they were buying up little plots of farmland and between, and I think some of these towers they actually had to pay these farmers - in the regions of $500 million just to put a tower there. I think that's particularly interesting because I think when we are building sites and apps and throwing them in a browser and we are delivering this HTML, right, and, as you saw in the previous talk, we are getting better at detecting the resources on the page and pre-getting them, but up to now, what we've been doing is this:  we're just throwing things at the customer. Saying take it all, I don't care about you. Whether on a tiny phone with a slow CPU, or maybe you've used all your data plan, like I have in Berlin already in a week, we're not doing enough here. I'm going to take you through some stats about the state of global connectivity. Right now, there are 7.4 billion people on the planet. 46 per cent of them have access to the internet. That means that we are actually at a point where there are four billion people who don't have any access to the internet at all. We're only halfway there. We're not even halfway there yet. So why don't we have an a look at how quickly the internet is growing, and if you were thinking maybe Europe is getting better connectivity, maybe it's US, 300 million people there, may be it is in Australia where I'm from, and really trying to build a faster internet, but struggling, it isn't really sort of in that bubble that we are in right now today. If you look at India just last year, their internet users grew by 108 million people, which, in case you were wondering, that's more than the population of Germany. This is 30 per cent year on year from the year previously. If those numbers are matched again this year, that will be 140 million people.  Airtel, who are the largest carrier, have 255 million customers, people who just have a phone plan, and this stat, the last time I researched it, it's gone up by 5 million subscribers, and their share has fallen from 32 per cent of the marketplace. Truly, truly incredible numbers. In India only 635 per cent 1.2 billion don't have access to the internet, so that means that's 864 million people who are yet to get the internet. They're about to. That's essential lit population of China again. I took time to look at what data costs in different locations. The way that I came up with these numbers here is I took a pre-paid plan, which is usually cheaper than a post-paid plan, and I took the minimum wage of these countries, and I calculated how many hours would you have to work just to get 500megs of data. In India, it is it is 17 hours, but in Germany, it is less than one hour. Our, let's call it, data addiction isn't met with the same enthusiasm in other places in the world. Could I get some water?  Thank you. That could be one hour for eight songs on Spotify, six minutes of YouTube, and less than an hour playing games. Or you can go to the Burj, empty your cache and hit reload 28 times. Even if you can afford the internet, you're not necessarily going to get fast internet all the time. Back in Melbourne last year, I lived on the wrong side of the street to get cable connection so I ended up having DSL and it was a lot slower than it should have been. Even if you have LTE advertise the on your phone, you may not get the same LTE speeds. In Singapore, the average is capping out at about 50 which is super great, but in India, it is doing 6.39Mbit/s. It's no matter where you are in the world. I had a look at the German internet plans because I'm Australian, and it's very different here. I Shaw that there are 400 Mbit connections. Over the year if it worked out to EUR30 a month. Put that on a global scale, does anyone want to guess where the global average for connection speed would be?  Shout out numbers?  Two?  50?  50. Okay. It is actually seven. This is the global average. So this is, it is pulled down by some places and pulled up by others. I thought maybe we could look at the mobile speed. In Canada, which is covering the Americas region, the best average, or the highest average speed is 10.3. In Australia, for Asia-Pacific, 13. For the United Kingdom, Europe, it was 26.8 - [Laughter]  - and the UAE for the Middle East and Africa region was 17.2. But it goes further than that. 60 per cent of all but global mobile connections are actually 2G. So we know that, even if you do have LTE, you can't really assume it's going to be fast. On average, we're only doing 7Mbit a second. Let's look at devices. Most devices on the web are handsets. This has been the case since 2014. I thought maybe I would have a look. I have an iPhone in my pocket, and I'm sure a lot of you do too, and maybe use an android, and that is cool too. Have you thought of devices that people use in other locations?  Here are the top five devices for three regions. China had three phones I had never heard of, and they were selling enough devices to cover the population of my country multiple times over a year, so that's reasonably significant. The I don't know hands in India is corresponding to its very mixed market but it is a big collection of devices. So, I got to wondering, is there a single device that best represents average?  If we need to - we know that these devices are super, super different. How do we test this and understand what to do next?  Thanks to our friends at Google, there's been some research done into this. At the moment today, if you were to take a fairly average phone, it is not super expensive, I think in Germany, it is EUR180 if you were to go and buy one won you would end up with a quad core CPU, decent amount of storage. This isn't the slow phone that people will tell you in talks you have to think about these other people, this is a pretty middle-of-the-road phobe. It is not the fastest and it is not the slowest. If you average out global devices, this is where you will end up. Has really great. You can test them on web page tests, and they have these devices in data centres around the world. Let's say you didn't have access to a device. Here's what you can do. Go into your current dev tools. Click on the timeline. Click on "capture settings" CPU, drag it down to 5. I know 5 is seemingly an abstract number, but if you're on a recent Macbook Pro, you will end up with the speed of about a MotoG4. There's been research done into this, and you can calibrate your device, but if you're looking for a close enough experience, that's where you should end up. 5x slowdown. What is clear after we've looked at connectivity and devises is there aren't any context. If you go for a proper average, it changes daily. I like to think that there are two versions of the internet. There's the one that we use - us - and then there's one that we usually don't. I've been experiencing a little bit of the column B in the last couple of weeks here in Germany, and the aeroplane Wi-Fi I think at times was better than the Airbnb I have at the moment. The conference Wi-Fi hasn't been too bad - thanks for doing OK on that, JSConf - and Lie-fi when it says you're on Wi-Fi and nothing happens. We know that the connections vary and it might be that because you're at the wrong end of the building, and too many brick walls, or for whatever fucking reason, your modem needs restarting again. It happens, I understand. One thing is clear, we need to stop optimising for $3,000 computer with fast connections. Inconsistency is a major property of the web in general, but now that we are understanding that we are in a global landscape, it is time that we started by about what we are delivering to people so we should gather knowledge and build with more understanding and empty. Looking beyond the delivery of an asset or looking how an asset is put down on to a device, we are generally looking at three things:  delivery, so this is the time where we are saying how many scripts are there on this page?  How big are they?  What do they look like?  There is the pass cycle. This is when the browser gets those assets, and it has to figure out something. Maybe it has to decompress the G zip on a resource, maybe it has to parse and compile the JavaScript, maybe it has to get an image and then composite it before it actually paints it. The last part of that is run time. These three phases of performance that we should worry about. Runtime is actually the actual run time that we are giving smooth, fluid animations and making it responsive to a user input. But unfortunately at the moment, the one rear really forgetting this is parse time. We're throwing down scripts at the browser and we're just hoping for the best.  This wonderful graphic is taken from a brilliant blog post called JavaScript start-up time and a rough how V8 works or more like, the V8 people tell me, how it will work really soon. This varies from engine to engine, but they take your JS, they generate byte code, do optimisation stuff, and then they build it for your architecture. When you're taking the 410 average script size, this is the average across the web, right?  This is what we are on average setting. There's been the argument that maybe we can reduce that size, just remove a jpeg - I won't name names - but this became a bit of a popular thing to say a couple of years ago, but I tell you why it's wrong. Forget 410kb. When you decompress, it could be three to four megabytes. It is the three to four megabytes that your phone has to understand, compile. I took the JSConf site which is really light, whoever worked on it didn't have to do much stuff to make a pretty website to tell you about the conference - it only had 57KB-of-scripts, jQuery, some web stats and a tiny 1kb. When I bench marked it on desktop, this one, and a MotoG4, I found that the script time, all I'm dealing is loading the page, and we are spending three times the amount of time just in scripting. Why is that important?  It is important because this is happening in the JavaScript main thread. This is also blogging Paint, and in these are all the little things that make your website feel when you're also contending with web fonts loading, and disappearing, and a different one appears, and a user is controlling, and then an image loads and then that pops back up - you've all even is, right?  We are suspect to it. I look the Lufthansa site this this is the mobile site. This is probably reasonably optimised. On average, a little bit bigger than other stuff. And it actually compressed really, really well, and, again, well, it was double. It doesn't mean that these numbers are completely linear. You can't say that it's going to be 600kB. You do need to test that stuff. I did start testing. Let's do an experiment here. Maybe I can just say, "Delete all of your JavaScript". You might not like that be. So I took the Guardian's website. They've done some fantastic work. Patrick Hammond who is here spoke two years ago at CSSConf, and he showed all the really great work he's done at the Guardian. I don't want to bash it up too much, but I'm going to show you something. This is the Guardian loading side by side. On the left, we have it without JavaScript and on the right, we have it with. The version on the left was completely visible in under 5 seconds on a 3G connection - bang, done. The other side:  well, there is the fonts, switching, loading. The weather appeared and then a related article appeared at the bottom of the screen and it stopped rendering somewhere around the 22-second mark. Unfortunately, the 22-second mark is about the average. The average for this is about 17 seconds. This is not a bad website. This is very, very normal.  It goes further too. Of the difference between the requests, and it wasn't all JavaScript, it was images and assets and other stuff, we, with JavaScript, it was 3.4 megabytes, 115 requests, otherwise 1.59 and 61 requests. I think that's a lot just to show people a related article and whether and different [sound cut] but we didn't really improve it. We talk about progressive enhancement [sound cut] one thing that I've really noticed this that the metrics we're currently - I think they are the important part. Metrics like unload, on DOM-content loaded which is everything ready, DOM ready, and speed index which is my particular favourite to have a little go at. I know people who put "MS" after it so that is looks ... good metrics try to aim something. Here are some examples of good metrics. Has 19 heard of them?  Any of them, all of them?  I'm going to explain a little bit about what they are. The user navigates. We have a first paint. The first paint is when we see anything a wide screen. We go on, render a little bit more. Then we have some more graphic starting to appear, the font hasn't uploaded yet, and then we get to a point where we get the meaningful paint. That means that the text is visible, somebody did see something readable approximately visually complete means when the area in the view port is fully resolved, let's call it. That's great. Visually complete is a difficult one. It is not something that you do get out of dev tools, so how can we produce these metrics and actually get something out of it. Thankfully, there's a tool called Lighthouse built by the Google Chrome team which comes as a browser extension. And you can just go to a website, click on it, generate a report. It loads the site by default in nexus 5x, I think, and it slows the CPU down, it checks it in an offline mode, it will give you some stats with how it's performing as a progressive web app, accessibility stuff request and best practices. That's really great. I have a little secret though:  can we keep this between us?  Yes. As of Thursday, Lighthouse dropped into Google Chrome can nary. I will show you how to get this now. You need the latest Chrome Canary and animate, I imagine. You need to go to the chrome Flags page, search for dev tools experiments and turn that on. Then relaunch your browser - this is quite a step. Go to the thing that you want, and pop up your dev tools, go to the settings down here, over to the experiments, you don't see it, right?  See how it appeared. You have to hit shift. It's a little secret. Then they appear, all those things that you didn't know were there. Then you have to turn it on. Close it. Open it again, and audits two will appear. Then you get a lighthouse button and you can choose the audits that you want to do and you will get some idea of the performance of your browser. I'm not sure when this is going to reach stable but they're working hard on it Google IOs in a week and a half and the guys have been worked really, really half. First meaningful paint, visually complete. I'm going to talk to you about a what this other metric we've heard a little bit about is. It is time to visually complete. This is how they're calculating it now in lighthouse. I think it is really, really cool. We watch the timeline and we figure out when the browser is visually complete, and then we are watching the JavaScript main thread,and we're watching the sub tasks that are happening, looking for them that are shorter than 50 milliseconds. We figure out when there is a five-second window without a long Taft, task. The reason we do that because time to interactive is a really good way of getting that empathy for a user that it's not popping around the web fonts nor and it's not jumping up and down and going all over the place. Your target for every device, and I'm talking about the phones in your pockets is to get it in under five seconds. Even better come up with the Twitter team do having a metric of time to first Tweet. They've been doing it for years. Trying to find ways of understanding how your users are using your apps and sites and get a metric and track it. Because it doesn't matter when unload happens. It is totally irrelevant. Don't try and keep people on your side for as long as possible. Help them get to their goals and do it quickly so they can do something else which is far better. I know that the performance landscape is realising fast and so many bits and pieces to worry about. My advice is to pick one or two and give them a shot. All of these things that are on the screen here, using a CDN, like weapon P, the purple pattern, all of these will improve website performance, give one of them a go, test it, measure it and improve. If you're wondering where I got the stats from, they are from the State of the Internet report?  Has anyone seen this before?  Like ten people, I think. It is a quarterly report put out, so, all my data is from Q42016, and it is just a pdf report. You can see what the global averages are. The global average for connection speed went from 62M/bit per second to the 7. We are improving but it is very slow. We've been focused on the wealthy Western web for so long, we're building for the machines we're using, but that's bullshit. We didn't sign up for that. We signed up for the World Wide Web. I want to encourage you to make the web faster, everyone. That's what I'm trying to do at Calibre, and that's what I'm dedicating all my work to at the moment. Hopefully, you can get Calibre, give it a shot. If you don't, try Lighthouse, that's great. Otherwise, if you want stickers, come and see me or something. It will be cool. Thanks a lot. [Applause].  
>> You have literally 60 seconds to get coffee or snacks. Run!  Are we ready?  We're really not ready!  